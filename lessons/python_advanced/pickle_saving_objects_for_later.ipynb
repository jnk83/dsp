{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python Version:\", sys.version, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle: Saving Objects for Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in data science, we'll create some model or some version of our data and want to use it later. We have many options - we can save the coefficients, or save the data to csv, or...\n",
    "\n",
    "Actually, we don't have that many options. \n",
    "\n",
    "One way to overcome that is to save the python object to a file as a serialized object. That means we convert the entire object to a bunch of bytes, save those bytes into a file, and then have the ability to unpack those bytes back into their original format later. \n",
    "\n",
    "This is done by a module called `pickle`. Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "lots_of_noise = {\n",
    "    'CA': [random.randint(0,65) for _ in range(100)],\n",
    "    'IL': [random.randint(0,65) for _ in range(50)],\n",
    "    'NY': [random.randint(0,65) for _ in range(90)],\n",
    "    'WA': [random.randint(0,65) for _ in range(33)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': [20, 20, 15, 56, 4, 18, 47, 13, 10, 6, 47, 10, 52, 36, 64, 20, 25, 27, 20, 61, 17, 25, 1, 65, 32, 34, 58, 59, 13, 42, 59, 4, 56, 19, 5, 37, 60, 53, 22, 10, 20, 18, 4, 39, 52, 41, 63, 19, 22, 57, 61, 51, 23, 29, 25, 24, 58, 8, 62, 32, 1, 20, 45, 5, 39, 54, 43, 30, 59, 34, 59, 25, 24, 51, 43, 41, 43, 13, 57, 62, 15, 13, 4, 4, 48, 32, 47, 37, 11, 57, 2, 18, 27, 19, 48, 63, 31, 7, 59, 13], 'IL': [22, 54, 44, 43, 58, 24, 59, 32, 20, 16, 19, 32, 23, 38, 10, 13, 57, 34, 17, 8, 22, 28, 21, 16, 42, 13, 53, 15, 62, 37, 14, 35, 36, 39, 15, 57, 21, 17, 65, 60, 4, 7, 10, 12, 62, 31, 4, 8, 42, 2], 'NY': [35, 51, 1, 27, 22, 14, 22, 59, 16, 23, 31, 4, 23, 48, 22, 44, 27, 16, 32, 48, 59, 52, 30, 18, 56, 30, 7, 47, 58, 37, 9, 49, 7, 20, 13, 41, 32, 9, 41, 17, 20, 15, 34, 37, 12, 47, 52, 20, 17, 49, 56, 6, 53, 2, 22, 5, 6, 18, 28, 0, 61, 2, 39, 4, 50, 0, 41, 16, 59, 14, 33, 36, 44, 13, 30, 26, 45, 1, 30, 18, 52, 27, 16, 41, 62, 36, 52, 3, 21, 6], 'WA': [19, 46, 26, 8, 39, 20, 9, 14, 3, 23, 17, 11, 54, 44, 45, 50, 48, 35, 34, 34, 20, 52, 25, 11, 13, 40, 24, 14, 3, 32, 8, 49, 57]}\n"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type      Data/Info\n",
      "-----------------------------------\n",
      "lots_of_noise   dict      n=4\n",
      "pickle          module    <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "random          module    <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this `whos` command that the object `lots_of_noise` exists and is a `dict` with 4 keys. Nice. Now let's look at our file system and verify that there isn't a file called `noise.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 4408-83E8\n",
      "\n",
      " Directory of C:\\Users\\Josh\\Documents\\GitHub\\dsp\\lessons\\python_advanced\n",
      "\n",
      "03/16/2020  02:50 PM    <DIR>          .\n",
      "03/16/2020  02:50 PM    <DIR>          ..\n",
      "03/16/2020  02:02 PM    <DIR>          .ipynb_checkpoints\n",
      "03/16/2020  01:53 PM            17,244 advanced_python_datatypes.ipynb\n",
      "03/16/2020  02:00 PM             9,665 deep_and_shallow_copy.ipynb\n",
      "03/10/2020  03:45 PM    <DIR>          deep_copy_demo\n",
      "03/10/2020  03:45 PM             1,482 instructor_guide_week1_day4.md\n",
      "03/10/2020  03:45 PM             4,040 my_dataframe.pickle\n",
      "03/10/2020  03:45 PM               610 noise.pickle\n",
      "03/16/2020  02:50 PM             6,738 pickle_saving_objects_for_later.ipynb\n",
      "03/10/2020  03:45 PM               988 readme.md\n",
      "               7 File(s)         40,767 bytes\n",
      "               4 Dir(s)  545,708,081,152 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're ready to create a file and write the bytes to it. To do this with `pickle`, we use python's read-write streamer `open` and create a writable-binary (`wb`) file. We'll then use `pickle.dump` to put an object into that file as a string of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lots_of_noise, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 4408-83E8\n",
      "\n",
      " Directory of C:\\Users\\Josh\\Documents\\GitHub\\dsp\\lessons\\python_advanced\n",
      "\n",
      "03/16/2020  02:52 PM    <DIR>          .\n",
      "03/16/2020  02:52 PM    <DIR>          ..\n",
      "03/16/2020  02:02 PM    <DIR>          .ipynb_checkpoints\n",
      "03/16/2020  01:53 PM            17,244 advanced_python_datatypes.ipynb\n",
      "03/16/2020  02:00 PM             9,665 deep_and_shallow_copy.ipynb\n",
      "03/10/2020  03:45 PM    <DIR>          deep_copy_demo\n",
      "03/10/2020  03:45 PM             1,482 instructor_guide_week1_day4.md\n",
      "03/10/2020  03:45 PM             4,040 my_dataframe.pickle\n",
      "03/16/2020  02:52 PM               610 noise.pickle\n",
      "03/16/2020  02:52 PM            10,706 pickle_saving_objects_for_later.ipynb\n",
      "03/10/2020  03:45 PM               988 readme.md\n",
      "               7 File(s)         44,735 bytes\n",
      "               4 Dir(s)  545,708,634,112 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete `lots_of_noise` and prove to ourselves it doesn't exist in Python's memory anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lots_of_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type              Data/Info\n",
      "--------------------------------------\n",
      "pickle     module            <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "random     module            <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "to_write   BufferedWriter    <_io.BufferedWriter name='noise.pickle'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lots_of_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-69f22b4d5ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlots_of_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lots_of_noise' is not defined"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely. It's dead forever. Or is it?\n",
    "\n",
    "Let's open that `noise.pickle` file with read-binary (`rb`) mode. Then we'll ask pickle to retrieve the file with `pickle.load` and store it back in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle','rb') as read_file:\n",
    "    new_noise = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': [20, 20, 15, 56, 4, 18, 47, 13, 10, 6, 47, 10, 52, 36, 64, 20, 25, 27, 20, 61, 17, 25, 1, 65, 32, 34, 58, 59, 13, 42, 59, 4, 56, 19, 5, 37, 60, 53, 22, 10, 20, 18, 4, 39, 52, 41, 63, 19, 22, 57, 61, 51, 23, 29, 25, 24, 58, 8, 62, 32, 1, 20, 45, 5, 39, 54, 43, 30, 59, 34, 59, 25, 24, 51, 43, 41, 43, 13, 57, 62, 15, 13, 4, 4, 48, 32, 47, 37, 11, 57, 2, 18, 27, 19, 48, 63, 31, 7, 59, 13], 'IL': [22, 54, 44, 43, 58, 24, 59, 32, 20, 16, 19, 32, 23, 38, 10, 13, 57, 34, 17, 8, 22, 28, 21, 16, 42, 13, 53, 15, 62, 37, 14, 35, 36, 39, 15, 57, 21, 17, 65, 60, 4, 7, 10, 12, 62, 31, 4, 8, 42, 2], 'NY': [35, 51, 1, 27, 22, 14, 22, 59, 16, 23, 31, 4, 23, 48, 22, 44, 27, 16, 32, 48, 59, 52, 30, 18, 56, 30, 7, 47, 58, 37, 9, 49, 7, 20, 13, 41, 32, 9, 41, 17, 20, 15, 34, 37, 12, 47, 52, 20, 17, 49, 56, 6, 53, 2, 22, 5, 6, 18, 28, 0, 61, 2, 39, 4, 50, 0, 41, 16, 59, 14, 33, 36, 44, 13, 30, 26, 45, 1, 30, 18, 52, 27, 16, 41, 62, 36, 52, 3, 21, 6], 'WA': [19, 46, 26, 8, 39, 20, 9, 14, 3, 23, 17, 11, 54, 44, 45, 50, 48, 35, 34, 34, 20, 52, 25, 11, 13, 40, 24, 14, 3, 32, 8, 49, 57]}\n"
     ]
    }
   ],
   "source": [
    "print(new_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable    Type              Data/Info\n",
      "---------------------------------------\n",
      "new_noise   dict              n=4\n",
      "pickle      module            <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "random      module            <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "read_file   BufferedReader    <_io.BufferedReader name='noise.pickle'>\n",
      "to_write    BufferedWriter    <_io.BufferedWriter name='noise.pickle'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random noise lives! We retrieved the entire structure from file. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, but I don't use dictionaries... I use pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yay</th>\n",
       "      <th>specific</th>\n",
       "      <th>column</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.294879</td>\n",
       "      <td>6.314376</td>\n",
       "      <td>1.962309</td>\n",
       "      <td>-1.046327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.347777</td>\n",
       "      <td>-9.717394</td>\n",
       "      <td>0.889821</td>\n",
       "      <td>-9.646189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.209924</td>\n",
       "      <td>-9.256731</td>\n",
       "      <td>-9.300143</td>\n",
       "      <td>-3.782189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.493435</td>\n",
       "      <td>-4.888127</td>\n",
       "      <td>6.625085</td>\n",
       "      <td>6.521841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.505370</td>\n",
       "      <td>-6.082840</td>\n",
       "      <td>9.185483</td>\n",
       "      <td>-1.836351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yay  specific    column     names\n",
       "0  9.294879  6.314376  1.962309 -1.046327\n",
       "1  5.347777 -9.717394  0.889821 -9.646189\n",
       "2  2.209924 -9.256731 -9.300143 -3.782189\n",
       "3  9.493435 -4.888127  6.625085  6.521841\n",
       "4 -6.505370 -6.082840  9.185483 -1.836351"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.uniform(-10,10, size=(100,4)), columns=['Yay','specific','column','names'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataframe.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3975f6306adf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "del df\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yay</th>\n",
       "      <th>specific</th>\n",
       "      <th>column</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.294879</td>\n",
       "      <td>6.314376</td>\n",
       "      <td>1.962309</td>\n",
       "      <td>-1.046327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.347777</td>\n",
       "      <td>-9.717394</td>\n",
       "      <td>0.889821</td>\n",
       "      <td>-9.646189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.209924</td>\n",
       "      <td>-9.256731</td>\n",
       "      <td>-9.300143</td>\n",
       "      <td>-3.782189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.493435</td>\n",
       "      <td>-4.888127</td>\n",
       "      <td>6.625085</td>\n",
       "      <td>6.521841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.505370</td>\n",
       "      <td>-6.082840</td>\n",
       "      <td>9.185483</td>\n",
       "      <td>-1.836351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yay  specific    column     names\n",
       "0  9.294879  6.314376  1.962309 -1.046327\n",
       "1  5.347777 -9.717394  0.889821 -9.646189\n",
       "2  2.209924 -9.256731 -9.300143 -3.782189\n",
       "3  9.493435 -4.888127  6.625085  6.521841\n",
       "4 -6.505370 -6.082840  9.185483 -1.836351"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('my_dataframe.pickle','rb') as read_file:\n",
    "    new_df = pickle.load(read_file)\n",
    "    \n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is a great tool. One recommended way of using it is to make it an end point of every step in your process. Example:\n",
    "\n",
    "* I got my data! Nice. Pickle it and stop your \"getting the data\" notebook.\n",
    "* Load your data from pickle. Clean it. Save your clean data to a new pickle.\n",
    "* Load your cleaned_data pickle. Do analysis and visualize it.\n",
    "\n",
    "This can provide natural \"pick-up-where-I-left-off-but-before-I-broke-my-data\" points. It's a great way to control the flow of your data.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "https://docs.python.org/3.7/library/pickle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
